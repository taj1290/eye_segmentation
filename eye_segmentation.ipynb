{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "eye_segmentation.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "w2JWZV6CoTZd"
      },
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "import random\n",
        "\n",
        "def rotateImage(image, angle):\n",
        "    image_center=tuple(np.array(image.shape[1::-1])/2)\n",
        "    rot_mat=cv2.getRotationMatrix2D(image_center, angle, 1.0)\n",
        "    result=cv2.warpAffine(image, rot_mat, image.shape[1::-1], flags=cv2.INTER_LINEAR)\n",
        "    return result\n",
        "\n",
        "def bruit(image):\n",
        "    h, w, c=image.shape\n",
        "    n=np.random.randn(h, w, c)*random.randint(5, 30)\n",
        "    return np.clip(image+n, 0, 255).astype(np.uint8)\n",
        "\n",
        "def change_gamma(image, alpha=1.0, beta=0.0):\n",
        "    return np.clip(alpha*image+beta, 0, 255).astype(np.uint8)\n",
        "\n",
        "def color(image, alpha=20):\n",
        "    n=[random.randint(-alpha, alpha), random.randint(-alpha, alpha),random.randint(-alpha, alpha)]\n",
        "    return np.clip(image+n, 0, 255).astype(np.uint8)\n",
        "\n",
        "def random_change(image):\n",
        "    if np.random.randint(2):\n",
        "        img=change_gamma(image, random.uniform(0.8, 1.2), np.random.randint(100)-50)\n",
        "    if np.random.randint(2):\n",
        "        img=bruit(image)\n",
        "    if np.random.randint(2):\n",
        "        img=color(image)\n",
        "    return image"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5XZjU3o3rj68"
      },
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers, models\n",
        "\n",
        "def model(nbr):\n",
        "    entree=layers.Input(shape=(576, 560, 3), dtype='float32')\n",
        "\n",
        "    result=layers.Conv2D(nbr, 3, activation='relu', padding='same')(entree)\n",
        "    result=layers.BatchNormalization()(result)\n",
        "    result=layers.Conv2D(nbr, 3, activation='relu', padding='same')(result)\n",
        "    result1=layers.BatchNormalization()(result)\n",
        "\n",
        "    result=layers.MaxPool2D()(result1)\n",
        "\n",
        "    result=layers.Conv2D(2*nbr, 3, activation='relu', padding='same')(result)\n",
        "    result=layers.BatchNormalization()(result)\n",
        "    result=layers.Conv2D(2*nbr, 3, activation='relu', padding='same')(result)\n",
        "    result2=layers.BatchNormalization()(result)\n",
        "\n",
        "    result=layers.MaxPool2D()(result2)\n",
        "\n",
        "    result=layers.Conv2D(4*nbr, 3, activation='relu', padding='same')(result)\n",
        "    result=layers.BatchNormalization()(result)\n",
        "    result=layers.Conv2D(4*nbr, 3, activation='relu', padding='same')(result)\n",
        "    result3=layers.BatchNormalization()(result)\n",
        "\n",
        "    result=layers.MaxPool2D()(result3)\n",
        "\n",
        "    result=layers.Conv2D(4*nbr, 3, activation='relu', padding='same')(result)\n",
        "    result=layers.BatchNormalization()(result)\n",
        "    result=layers.Conv2D(4*nbr, 3, activation='relu', padding='same')(result)\n",
        "    result4=layers.BatchNormalization()(result)\n",
        "\n",
        "    result=layers.MaxPool2D()(result4)\n",
        "\n",
        "    result=layers.Conv2D(8*nbr, 3, activation='relu', padding='same')(result)\n",
        "    result=layers.BatchNormalization()(result)\n",
        "    result=layers.Conv2D(4*nbr, 3, activation='relu', padding='same')(result)\n",
        "    result=layers.BatchNormalization()(result)\n",
        "\n",
        "    result=layers.UpSampling2D()(result)\n",
        "    result=tf.concat([result, result4], axis=3)\n",
        "\n",
        "    result=layers.Conv2D(8*nbr, 3, activation='relu', padding='same')(result)\n",
        "    result=layers.BatchNormalization()(result)\n",
        "    result=layers.Conv2D(4*nbr, 3, activation='relu', padding='same')(result)\n",
        "    result=layers.BatchNormalization()(result)\n",
        "\n",
        "    result=layers.UpSampling2D()(result)\n",
        "    result=tf.concat([result, result3], axis=3)\n",
        "    \n",
        "    result=layers.Conv2D(4*nbr, 3, activation='relu', padding='same')(result)\n",
        "    result=layers.BatchNormalization()(result)\n",
        "    result=layers.Conv2D(2*nbr, 3, activation='relu', padding='same')(result)\n",
        "    result=layers.BatchNormalization()(result)\n",
        "\n",
        "    result=layers.UpSampling2D()(result)\n",
        "    result=tf.concat([result, result2], axis=3)\n",
        "    \n",
        "    result=layers.Conv2D(2*nbr, 3, activation='relu', padding='same')(result)\n",
        "    result=layers.BatchNormalization()(result)\n",
        "    result=layers.Conv2D(nbr, 3, activation='relu', padding='same')(result)\n",
        "    result=layers.BatchNormalization()(result)\n",
        "    \n",
        "    result=layers.UpSampling2D()(result)\n",
        "    result=tf.concat([result, result1], axis=3)\n",
        "    \n",
        "    result=layers.Conv2D(nbr, 3, activation='relu', padding='same')(result)\n",
        "    result=layers.BatchNormalization()(result)\n",
        "    result=layers.Conv2D(nbr, 3, activation='relu', padding='same')(result)\n",
        "    result=layers.BatchNormalization()(result)\n",
        "\n",
        "    sortie=layers.Conv2D(1, 1, activation='sigmoid', padding='same')(result)\n",
        "\n",
        "    model=models.Model(inputs=entree, outputs=sortie)\n",
        "    return model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N4YIFt1S4kjy",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 229
        },
        "outputId": "ec7306fa-bde1-446a-d17f-55a4ab2e43f1"
      },
      "source": [
        "import tensorflow as tf\n",
        "from sklearn.model_selection import train_test_split\n",
        "from PIL import Image\n",
        "import os\n",
        "import numpy as np\n",
        "import random\n",
        "import cv2\n",
        "#import model\n",
        "#import traitement_images as ti\n",
        "\n",
        "dir_images='drive/MyDrive/DRIVE/training/images/'\n",
        "dir_mask  ='drive/MyDrive/DRIVE/training/1st_manual/'\n",
        "\n",
        "if not os.path.isdir(dir_images):\n",
        "    quit(\"The directory {} don't exist !\".format(dir_images))\n",
        "if not os.path.isdir(dir_mask):\n",
        "    quit(\"The directory {} don't exist !\".format(dir_mask))\n",
        "\n",
        "tab_images=[]\n",
        "tab_masks=[]\n",
        "\n",
        "list_file=os.listdir(dir_images)\n",
        "if list_file is None:\n",
        "    quit(\"No file in {} !\".format(dir_images))\n",
        "    \n",
        "for fichier in list_file:\n",
        "    img_orig=cv2.imread(dir_images+fichier)\n",
        "    tab_images.append(img_orig[:576, :560])\n",
        "    num=fichier.split('_')[0]\n",
        "    file_mask=dir_mask+num+'_manual1.gif'\n",
        "    if not os.path.isfile(file_mask):\n",
        "        quit(\"Mask of {} don't exist in {}\".format(file_mask, dir_mask))\n",
        "    img_mask_orig=np.array(Image.open(file_mask))\n",
        "    tab_masks.append(img_mask_orig[:576, :560])\n",
        "\n",
        "    for angle in range(0, 360, 30):\n",
        "        img_r=rotateImage(img_orig, angle)\n",
        "        img=img_r.copy()\n",
        "        img=random_change(img)\n",
        "        tab_images.append(img[:576, :560])\n",
        "        img_mask=rotateImage(img_mask_orig, angle)\n",
        "        tab_masks.append(img_mask[:576, :560])\n",
        "        \n",
        "        img=cv2.flip(img_r, 0)\n",
        "        img=random_change(img)\n",
        "        tab_images.append(img[:576, :560])\n",
        "        img_m=cv2.flip(img_mask, 0)\n",
        "        tab_masks.append(img_m[:576, :560])\n",
        "\n",
        "        img=cv2.flip(img_r, 1)\n",
        "        img=random_change(img)\n",
        "        tab_images.append(img[:576, :560])\n",
        "        img_m=cv2.flip(img_mask, 1)\n",
        "        tab_masks.append(img_m[:576, :560])\n",
        "\n",
        "        img=cv2.flip(img_r, -1)\n",
        "        img=random_change(img)\n",
        "        tab_images.append(img[:576, :560])\n",
        "        img_m=cv2.flip(img_mask, -1)\n",
        "        tab_masks.append(img_m[:576, :560])\n",
        "\n",
        "tab_images=np.array(tab_images, dtype=np.float32)/255\n",
        "tab_masks =np.array(tab_masks,  dtype=np.float32)[:, :, :]/255"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-3-71a19ba9a566>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0mtab_masks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m \u001b[0mlist_file\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdir_images\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mlist_file\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m     \u001b[0mquit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"No file in {} !\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdir_images\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'drive/MyDrive/DRIVE/training/images/'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NXHUjgiHrou-",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 370
        },
        "outputId": "39959df9-c086-4815-9661-f7e3a3801f7f"
      },
      "source": [
        "train_images, test_images, train_masks, test_masks=train_test_split(tab_images, tab_masks, test_size=0.05)\n",
        "\n",
        "#del tab_images\n",
        "#del tab_masks\n",
        "\n",
        "my_model=model(64)\n",
        "\n",
        "my_model.compile(optimizer='adam',\n",
        "                 loss='binary_crossentropy',\n",
        "                 metrics=['accuracy'])\n",
        "my_model.fit(train_images,\n",
        "             train_masks,\n",
        "             epochs=5,\n",
        "             batch_size=4,\n",
        "             validation_data=(test_images, test_masks))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-4-20d359d5a136>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrain_images\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_images\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_masks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_masks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrain_test_split\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtab_images\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtab_masks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.05\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m#del tab_images\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m#del tab_masks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_split.py\u001b[0m in \u001b[0;36mtrain_test_split\u001b[0;34m(*arrays, **options)\u001b[0m\n\u001b[1;32m   2120\u001b[0m     \u001b[0mn_samples\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_num_samples\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marrays\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2121\u001b[0m     n_train, n_test = _validate_shuffle_split(n_samples, test_size, train_size,\n\u001b[0;32m-> 2122\u001b[0;31m                                               default_test_size=0.25)\n\u001b[0m\u001b[1;32m   2123\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2124\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mshuffle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_split.py\u001b[0m in \u001b[0;36m_validate_shuffle_split\u001b[0;34m(n_samples, test_size, train_size, default_test_size)\u001b[0m\n\u001b[1;32m   1803\u001b[0m             \u001b[0;34m'resulting train set will be empty. Adjust any of the '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1804\u001b[0m             'aforementioned parameters.'.format(n_samples, test_size,\n\u001b[0;32m-> 1805\u001b[0;31m                                                 train_size)\n\u001b[0m\u001b[1;32m   1806\u001b[0m         )\n\u001b[1;32m   1807\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: With n_samples=0, test_size=0.05 and train_size=None, the resulting train set will be empty. Adjust any of the aforementioned parameters."
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j9dEToxa4xqS"
      },
      "source": [
        "dir_test_images='drive/MyDrive/DRIVE/test/images/'\n",
        "\n",
        "tab_test_images=[]\n",
        "tab_files=[]\n",
        "for fichier in os.listdir(dir_test_images):\n",
        "    img=cv2.imread(dir_test_images+fichier)\n",
        "    tab_test_images.append(img[:576, :560])\n",
        "    tab_files.append(fichier.split('_')[0])\n",
        "\n",
        "tab_test_images=np.array(tab_test_images, dtype=np.float32)/255\n",
        "tab_files=np.array(tab_files)\n",
        "\n",
        "for id in range(len(tab_test_images)):\n",
        "    mask=np.zeros((584, 565, 1), dtype=np.float32)\n",
        "    prediction=my_model.predict(np.array([tab_test_images[id]]))\n",
        "    mask[:576, :560]=prediction[0]*255\n",
        "    cv2.imwrite(\"drive/MyDrive/DRIVE/predictions/\"+str(tab_files[id])+\".png\", mask)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}